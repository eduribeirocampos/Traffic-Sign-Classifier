{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eduardo Ribeiro de Campos - Udacity / SDCND - May./2019.\n",
    "\n",
    "\n",
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "## Project3: ** Traffic Sign Recognition** \n",
    "\n",
    "The goals / steps of this project are the following according to the  [rubric points](https://review.udacity.com/#!/rubrics/481/view) \n",
    "\n",
    "1. **Dataset Exploration**<br/> \n",
    "    1.1 Dataset summary.<br/> \n",
    "    1.2 Exploratory Visualization.<br/> \n",
    "    \n",
    "2. **Design and Test a Model Architecture**<br/> \n",
    "    2.1 Preprocessing.<br/>\n",
    "    2.2 Model Architecture.<br/>\n",
    "    2.3 Model Training.<br/>\n",
    "    2.4 Solution Approach.<br/>\n",
    "\n",
    "3. **Test a Model on New Images**<br/> \n",
    "    3.1 Acquiring New Images.<br/>\n",
    "    3.2 Performance on New Images.<br/>\n",
    "    3.3 Model Certainty - Softmax Probabilities.<br/>\n",
    "    \n",
    "\n",
    "**Here is a link to [code file](./Advanced_Lane_Finding.ipynb)**\n",
    "\n",
    "[//]: # (Image References)\n",
    "\n",
    "[image1]: ./output_images/dataset_expl_qty.jpg \n",
    "[image2]: ./output_images/dataset_expl_percent.jpg \n",
    "[image3]: ./output_images/dataset_German_traffic_signs.jpg \n",
    "\n",
    "[image4]: ./output_images/same_labes_examples1.jpg\n",
    "[image5]: ./output_images/same_labes_examples2.jpg\n",
    "[image6]: ./output_images/same_labes_examples3.jpg\n",
    "[image7]: ./output_images/same_labes_examples4.jpg\n",
    "[image8]: ./output_images/same_labes_examples5.jpg\n",
    "[image9]: ./output_images/same_labes_examples6.jpg\n",
    "\n",
    "\n",
    "[image10]: ./output_images/preprocessed_examples1.jpg\n",
    "[image11]: ./output_images/preprocessed_examples2.jpg\n",
    "[image12]: ./output_images/preprocessed_examples3.jpg\n",
    "\n",
    "[image13]: ./output_images/lenet.jpg\n",
    "\n",
    "[image14]: ./output_images/Training_process.jpg\n",
    "\n",
    "[image15]: ./output_images/New_images.jpg\n",
    "\n",
    "[image16]:  ./output_images/New_images_preprocessed.jpg\n",
    "\n",
    "[image17]:  ./output_images/5_New_images_selecteds.jpg\n",
    "\n",
    "[image18]:  ./output_images/5_New_images_predictions.jpg\n",
    "\n",
    "\n",
    "\n",
    "[image19]:  ./output_images/softmax_probabilities1.jpg\n",
    "[image20]:  ./output_images/softmax_probabilities2.jpg\n",
    "[image21]:  ./output_images/softmax_probabilities3.jpg\n",
    "[image22]:  ./output_images/softmax_probabilities4.jpg\n",
    "[image23]:  ./output_images/softmax_probabilities5.jpg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_____\n",
    "\n",
    "## 1 - Load the data set.\n",
    "\n",
    "### 1.1 - Dataset sumary.\n",
    "\n",
    "The dataset was analysed using dictionary function from python. The table below shows the summary.\n",
    "\n",
    "| Features         \t|           quantity | \n",
    "|:-----------------:|:------------------:| \n",
    "| training         \t|        34799       | \n",
    "| testing     \t\t|        12630 \t     |\n",
    "| Validation\t\t|         4410       |\n",
    "\n",
    "The image shape for the features is: 32x32x3\n",
    "\n",
    "The number of unique classes (Labels) is: 43\n",
    "\n",
    "The next histograms show the distribution for the labels for each set. (Train,Validation and Test).\n",
    "\n",
    "![alt text][image1]\n",
    "\n",
    "\n",
    "Regarding the label distribution for the datasets, it is possible identify that we have the approximately the same distributions from the percentiles of the labels comparing with the total for the each Dataset. The next histogram show the distribution:\n",
    "\n",
    "![alt text][image2]\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 - Exploratory Visualization.\n",
    "\n",
    "The Next picture shows the 43 Labels used as traffic signs dataset and the image of them.\n",
    "\n",
    "![alt text][image3]\n",
    "\n",
    "From the histogram, below it is possible see 7 differents images from the same Label. The Labels 2, 1 and 13 are the labels with more number of examples and the Labels 0, 19 and 37 are the labels with less number of examples.\n",
    "\n",
    "![alt text][image4]\n",
    "![alt text][image5]\n",
    "![alt text][image6]\n",
    "![alt text][image7]\n",
    "![alt text][image8]\n",
    "![alt text][image9]\n",
    "\n",
    "_____\n",
    "\n",
    "\n",
    "## 2 -Design and Test a Model Architecture.\n",
    "\n",
    "### 2.1 - Preprocessing.\n",
    "\n",
    "For the Pre- process was applied 3 steps to the image data.<br/>\n",
    "$1^{st}$ - Converted to gray scale.<br/>\n",
    "$2^{nd}$ - Normalized the image data using the formula (pixel - 128)/ 128<br/>\n",
    "$3^{rd}$ - reshape image to add channel and reach the shape:  32x32x1<br/>\n",
    "\n",
    "These techniques were chosen  to normalize the images, so that the data has mean zero and equal variance and ensure a shape to be correctly in the next steps. ( Tensorflow functions).\n",
    "\n",
    "The final results are shown below in 7 pictures as example for the labels 2,1 and 13:\n",
    "\n",
    "![alt text][image10]\n",
    "![alt text][image11]\n",
    "![alt text][image12]\n",
    "\n",
    "\n",
    "### 2.2 - Model Architecture.\n",
    "\n",
    "The Convolutional Neural networks used have the same architecture of the example for Lenet-5. Used in the Udacity class, but the difference is that the last Linear Layer was chane the value from 10 to 50. \n",
    "The architeture is: Two convolutional layers followed by one flatten layer, drop out layer, and Three fully connected linear layers.As the follow picture. \n",
    "\n",
    "![alt text][image13]\n",
    "Source: Yan LeCun / edited to adjust the new value for the last layer.\n",
    "\n",
    "Details about the architeture:\n",
    "\n",
    "**Input:** Image in GrayScale with the size: 32x32x1\n",
    "\n",
    "1. convolution 1: 32x32x1  -> 28x28x6  -> relu -> 14x14x6 (pooling)\n",
    "2. convolution 2: 14x14x6  -> 10x10x16 -> relu -> 5x5x16  (pooling)\n",
    "3.       flatten: 5x5x16   -> 400\n",
    "4.      drop out: 400      -> 120\n",
    "5.        linear: 120      -> 84\n",
    "6.        linear:  84      -> 50\n",
    "\n",
    "**Output:** Return the result of the 2nd fully connected layer. Size = 50\n",
    "\n",
    "It was canceled the last layer to check the accuracy for the validation Set, the results is very similar , but the results to predict the label for the images from the internet it was not good. For this reason was kept the architeture as the LeNet-5 example.\n",
    "\n",
    "\n",
    "### 2.3 - Model Training.\n",
    "\n",
    "Here working with a lower value for 'Batch_size', I have realized an opportunity to increase the accuracy over than 0.98 in the validation data set, but the results accuracy with the Dowloaded images is very bad.So it was necessary work with a high value for batch size. The Number of EPOCHS greather than 10 did not show advantages to justify use values higher than 10.\n",
    "the Learning rate have contributed working with values less than $10^{-3}$. Below the parameter values:\n",
    "\n",
    "EPOCHS = 10<br/>\n",
    "BATCH_SIZE = 200<br/>\n",
    "learning rate 0.001<br/>\n",
    "\n",
    "The training process was executed using the Tensor flow library. and could be checked from cells 20 to 26 in the [code file](./Advanced_Lane_Finding.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "### 2.4 - Solution Approach.\n",
    "\n",
    "The picture below shows the accuracy variation over each EPOCH:\n",
    "\n",
    "![alt text][image14].\n",
    "\n",
    "The Validation accuracy have accomplished the value above the target of the project 0.93.<br/>\n",
    "The parameter and the architeture were checked in order to reached a high accuracy with the new images from the internet. The results will be shown on the next part of this write up.\n",
    "\n",
    "____\n",
    "\n",
    "## 3 - Test a Model on New Images.\n",
    "\n",
    "### 3.1 - Acquiring New Images.\n",
    "\n",
    "The New images from the internet for German traffic signs could be see in this [link](./German_traffic_Signs_Download/original_images).\n",
    "\n",
    "It was neccesary crop the images to isolate the traffic signs and this step could be see in this [link](./German_traffic_Signs_Download/Manual_crop_images).\n",
    "\n",
    "\n",
    "To use the pictures to check the accuracy using the model trained and already explained previously, it was necessary load the data , add margins do adapt the traffic signs image to similar of the data set used ,it was  necessary also apply the `blur function` from the cv2 library ,before create the data set with the new images.\n",
    "\n",
    "Below it is possible to see that it was capture 15 pictures from  the internet.\n",
    "\n",
    "![alt text][image15].\n",
    "\n",
    "It was applied the same preprocessing function to match the new images to the others available on the data-set reference.\n",
    "\n",
    "![alt text][image16].\n",
    "\n",
    "\n",
    "Using the `random.sample` function , it was selected 5 picures to check the accuracy.\n",
    "Below the pictures selected.<br/>\n",
    "\n",
    "![alt text][image17].\n",
    "\n",
    "###    3.2 - Performance on New Images.\n",
    "\n",
    "Below we have the same five images and the OK title where the prediction have reached success.\n",
    "\n",
    "![alt text][image18].\n",
    "\n",
    "It is possible to see that our model under a small data set with only 5 images reach an accuracy value equal 1 (100%).\n",
    "\n",
    "\n",
    "###    3.3 - Model Certainty - Softmax Probabilities.\n",
    "\n",
    "In our example, using the Tensor flow function `tf.nn.top_k` and K value equal to 5. it is possible see  5 probabilities for each image.\n",
    "\n",
    "From the cells 45 to 49 were applied this function and the final result is an image showing in the left side the original image and the others 5 images in the same row are the probability to the model reach the success  to predict the traffic sign. It is possible have a look that in the 5 rows number the model hit the correct label. It is the same result shown in the performance on New Images (item 3.2) confirming the accuracy = 1.\n",
    "\n",
    "\n",
    "![alt text][image19].\n",
    "![alt text][image20].\n",
    "![alt text][image21].\n",
    "![alt text][image22].\n",
    "![alt text][image23].\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
